"""
EMRBots ë°ì´í„°ì…‹ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
ì‹¤ì œ ì˜ë£Œ ë°ì´í„°ì˜ íŒ¨í„´ì„ ì¶”ì¶œí•˜ì—¬ ëŒ€ê¸°ì—´ ë°ì´í„° ìƒì„±ì— í™œìš©
"""

from django.core.management.base import BaseCommand
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import os
import json

class Command(BaseCommand):
    help = 'Analyze EMRBots dataset to extract realistic hospital patterns'

    def handle(self, *args, **options):
        self.stdout.write("\nğŸ” EMRBots ë°ì´í„°ì…‹ ë¶„ì„ ì‹œì‘...")
        self.stdout.write("=" * 60)

        # ë°ì´í„° ê²½ë¡œ
        data_dir = os.path.join('data', 'emrbots_100')

        # 1. Admissions ë°ì´í„° ë¶„ì„
        self.stdout.write("\nğŸ“Š ì…ì› ë°ì´í„° ë¶„ì„...")
        admissions_df = self.load_admissions(data_dir)
        admission_patterns = self.analyze_admissions(admissions_df)

        # 2. Patients ë°ì´í„° ë¶„ì„
        self.stdout.write("\nğŸ‘¥ í™˜ì ë°ì´í„° ë¶„ì„...")
        patients_df = self.load_patients(data_dir)
        patient_patterns = self.analyze_patients(patients_df)

        # 3. Labs ë°ì´í„° ë¶„ì„
        self.stdout.write("\nğŸ§ª ê²€ì‚¬ ë°ì´í„° ë¶„ì„...")
        labs_df = self.load_labs(data_dir)
        lab_patterns = self.analyze_labs(labs_df)

        # 4. ì¢…í•© íŒ¨í„´ ìƒì„±
        self.stdout.write("\nğŸ“ˆ ì¢…í•© íŒ¨í„´ ìƒì„±...")
        combined_patterns = self.combine_patterns(
            admission_patterns,
            patient_patterns,
            lab_patterns
        )

        # 5. íŒ¨í„´ ì €ì¥
        self.save_patterns(combined_patterns)

        # 6. ê²°ê³¼ ì¶œë ¥
        self.print_analysis_summary(combined_patterns)

    def load_admissions(self, data_dir):
        """ì…ì› ë°ì´í„° ë¡œë“œ"""
        file_path = os.path.join(data_dir, 'AdmissionsCorePopulatedTable.txt')
        df = pd.read_csv(file_path, sep='\t', encoding='utf-8-sig')

        # ë‚ ì§œ ë³€í™˜
        df['AdmissionStartDate'] = pd.to_datetime(df['AdmissionStartDate'])
        df['AdmissionEndDate'] = pd.to_datetime(df['AdmissionEndDate'])

        # ì…ì› ê¸°ê°„ ê³„ì‚°
        df['LengthOfStay'] = (df['AdmissionEndDate'] - df['AdmissionStartDate']).dt.total_seconds() / 3600

        self.stdout.write(f"   - {len(df)}ê°œ ì…ì› ê¸°ë¡ ë¡œë“œ ì™„ë£Œ")
        return df

    def load_patients(self, data_dir):
        """í™˜ì ë°ì´í„° ë¡œë“œ"""
        file_path = os.path.join(data_dir, 'PatientCorePopulatedTable.txt')
        df = pd.read_csv(file_path, sep='\t', encoding='utf-8-sig')

        # ìƒë…„ì›”ì¼ ë³€í™˜
        df['PatientDateOfBirth'] = pd.to_datetime(df['PatientDateOfBirth'])

        # í˜„ì¬ ë‚˜ì´ ê³„ì‚° (2024ë…„ ê¸°ì¤€)
        df['Age'] = 2024 - df['PatientDateOfBirth'].dt.year

        self.stdout.write(f"   - {len(df)}ëª… í™˜ì ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
        return df

    def load_labs(self, data_dir):
        """ê²€ì‚¬ ë°ì´í„° ë¡œë“œ (ìƒ˜í”Œë§)"""
        file_path = os.path.join(data_dir, 'LabsCorePopulatedTable.txt')

        # íŒŒì¼ì´ í¬ë¯€ë¡œ ìƒ˜í”Œë§í•˜ì—¬ ë¡œë“œ
        df = pd.read_csv(file_path, sep='\t', encoding='utf-8-sig', nrows=10000)

        # ë‚ ì§œ ë³€í™˜
        df['LabDateTime'] = pd.to_datetime(df['LabDateTime'])

        self.stdout.write(f"   - {len(df)}ê°œ ê²€ì‚¬ ê¸°ë¡ ìƒ˜í”Œ ë¡œë“œ ì™„ë£Œ")
        return df

    def analyze_admissions(self, df):
        """ì…ì› íŒ¨í„´ ë¶„ì„"""
        patterns = {}

        # ì‹œê°„ëŒ€ë³„ ì…ì› ë¶„í¬
        df['AdmissionHour'] = df['AdmissionStartDate'].dt.hour
        hourly_dist = df['AdmissionHour'].value_counts(normalize=True).sort_index()
        patterns['hourly_admission'] = hourly_dist.to_dict()

        # ìš”ì¼ë³„ ì…ì› ë¶„í¬
        df['AdmissionWeekday'] = df['AdmissionStartDate'].dt.dayofweek
        weekday_dist = df['AdmissionWeekday'].value_counts(normalize=True).sort_index()
        patterns['weekday_admission'] = weekday_dist.to_dict()

        # ì…ì› ê¸°ê°„ í†µê³„
        patterns['length_of_stay'] = {
            'mean': float(df['LengthOfStay'].mean()),
            'median': float(df['LengthOfStay'].median()),
            'std': float(df['LengthOfStay'].std()),
            'min': float(df['LengthOfStay'].min()),
            'max': float(df['LengthOfStay'].max()),
            'q25': float(df['LengthOfStay'].quantile(0.25)),
            'q75': float(df['LengthOfStay'].quantile(0.75))
        }

        # ì›”ë³„ ì…ì› ë¶„í¬
        df['AdmissionMonth'] = df['AdmissionStartDate'].dt.month
        monthly_dist = df['AdmissionMonth'].value_counts(normalize=True).sort_index()
        patterns['monthly_admission'] = monthly_dist.to_dict()

        # ì¬ì…ì› íŒ¨í„´ (ê°™ì€ í™˜ìì˜ ì—¬ëŸ¬ ì…ì›)
        readmission_counts = df.groupby('PatientID').size()
        patterns['readmission'] = {
            'single_admission': float((readmission_counts == 1).mean()),
            'multiple_admissions': float((readmission_counts > 1).mean()),
            'avg_admissions_per_patient': float(readmission_counts.mean())
        }

        return patterns

    def analyze_patients(self, df):
        """í™˜ì íŒ¨í„´ ë¶„ì„"""
        patterns = {}

        # ì„±ë³„ ë¶„í¬
        gender_dist = df['PatientGender'].value_counts(normalize=True)
        patterns['gender_distribution'] = gender_dist.to_dict()

        # ì—°ë ¹ ë¶„í¬
        patterns['age_distribution'] = {
            'mean': float(df['Age'].mean()),
            'median': float(df['Age'].median()),
            'std': float(df['Age'].std()),
            'min': float(df['Age'].min()),
            'max': float(df['Age'].max())
        }

        # ì—°ë ¹ëŒ€ë³„ ë¶„í¬
        age_groups = pd.cut(df['Age'], bins=[0, 18, 35, 50, 65, 100],
                           labels=['0-18', '19-35', '36-50', '51-65', '65+'])
        age_group_dist = age_groups.value_counts(normalize=True).sort_index()
        patterns['age_groups'] = age_group_dist.to_dict()

        # ê²°í˜¼ ìƒíƒœ ë¶„í¬
        marital_dist = df['PatientMaritalStatus'].value_counts(normalize=True)
        patterns['marital_status'] = marital_dist.to_dict()

        return patterns

    def analyze_labs(self, df):
        """ê²€ì‚¬ íŒ¨í„´ ë¶„ì„"""
        patterns = {}

        # ì‹œê°„ëŒ€ë³„ ê²€ì‚¬ ë¶„í¬
        df['LabHour'] = df['LabDateTime'].dt.hour
        hourly_lab_dist = df['LabHour'].value_counts(normalize=True).sort_index()
        patterns['hourly_labs'] = hourly_lab_dist.to_dict()

        # ê²€ì‚¬ ì¢…ë¥˜ë³„ ë¹ˆë„
        lab_types = df['LabName'].value_counts(normalize=True).head(20)
        patterns['common_labs'] = lab_types.to_dict()

        # í™˜ìë‹¹ í‰ê·  ê²€ì‚¬ ìˆ˜
        labs_per_admission = df.groupby('AdmissionID').size()
        patterns['labs_per_admission'] = {
            'mean': float(labs_per_admission.mean()),
            'median': float(labs_per_admission.median()),
            'std': float(labs_per_admission.std())
        }

        return patterns

    def combine_patterns(self, admission_patterns, patient_patterns, lab_patterns):
        """ëª¨ë“  íŒ¨í„´ì„ ì¢…í•©í•˜ì—¬ ëŒ€ê¸°ì—´ ìƒì„±ìš© íŒ¨í„´ ìƒì„±"""
        combined = {
            'admissions': admission_patterns,
            'patients': patient_patterns,
            'labs': lab_patterns,
            'queue_patterns': {}
        }

        # ì‹œê°„ëŒ€ë³„ í˜¼ì¡ë„ (ì…ì› + ê²€ì‚¬ íŒ¨í„´ ê²°í•©)
        hourly_congestion = {}
        for hour in range(24):
            admission_weight = admission_patterns['hourly_admission'].get(hour, 0)
            lab_weight = lab_patterns['hourly_labs'].get(hour, 0)
            # ì…ì›ê³¼ ê²€ì‚¬ë¥¼ 6:4 ë¹„ìœ¨ë¡œ ê°€ì¤‘ í‰ê· 
            hourly_congestion[hour] = admission_weight * 0.6 + lab_weight * 0.4

        # ì •ê·œí™” (ìµœëŒ€ê°’ì„ 1ë¡œ)
        max_congestion = max(hourly_congestion.values()) if hourly_congestion else 1
        for hour in hourly_congestion:
            hourly_congestion[hour] = hourly_congestion[hour] / max_congestion

        combined['queue_patterns']['hourly_congestion'] = hourly_congestion

        # ìš”ì¼ë³„ íŒ¨í„´
        weekday_patterns = {}
        for day in range(7):
            weekday_patterns[day] = admission_patterns['weekday_admission'].get(day, 0.14)  # ê¸°ë³¸ê°’ 1/7

        combined['queue_patterns']['weekday_patterns'] = weekday_patterns

        # ë¶€ì„œë³„ ë§¤í•‘ (ê²€ì‚¬ ì¢…ë¥˜ë¥¼ ë¶€ì„œë¡œ ë§¤í•‘)
        department_mapping = {
            'METABOLIC': 'ì§„ë‹¨ê²€ì‚¬ì˜í•™ê³¼',
            'CBC': 'ì§„ë‹¨ê²€ì‚¬ì˜í•™ê³¼',
            'URINALYSIS': 'ì§„ë‹¨ê²€ì‚¬ì˜í•™ê³¼',
            'CARDIAC': 'ì‹¬ì¥ë‚´ê³¼',
            'BLOOD': 'ì±„í˜ˆì‹¤'
        }

        dept_distribution = {}
        for lab_name, freq in lab_patterns['common_labs'].items():
            for key, dept in department_mapping.items():
                if key in lab_name.upper():
                    dept_distribution[dept] = dept_distribution.get(dept, 0) + freq
                    break

        # ê¸°ë³¸ ë¶€ì„œ ì¶”ê°€
        default_depts = {
            'ë‚´ê³¼': 0.25,
            'ì •í˜•ì™¸ê³¼': 0.15,
            'X-rayì‹¤': 0.10,
            'CTì‹¤': 0.08,
            'MRIì‹¤': 0.05
        }

        for dept, weight in default_depts.items():
            if dept not in dept_distribution:
                dept_distribution[dept] = weight

        # ì •ê·œí™”
        total = sum(dept_distribution.values())
        if total > 0:
            for dept in dept_distribution:
                dept_distribution[dept] = dept_distribution[dept] / total

        combined['queue_patterns']['department_distribution'] = dept_distribution

        # ëŒ€ê¸°ì‹œê°„ íŒ¨í„´ (ì…ì› ê¸°ê°„ì„ ì°¸ì¡°)
        los_stats = admission_patterns['length_of_stay']

        # ì…ì› ì‹œê°„ì„ ë¶„ ë‹¨ìœ„ ëŒ€ê¸°ì‹œê°„ìœ¼ë¡œ ìŠ¤ì¼€ì¼ ë³€í™˜ (ì‹œê°„ -> ë¶„, ì ì ˆíˆ ì¶•ì†Œ)
        combined['queue_patterns']['wait_time_patterns'] = {
            'base_wait': min(los_stats['median'] * 2, 30),  # ì¤‘ì•™ê°’ì˜ 2ë°°ë¥¼ ë¶„ìœ¼ë¡œ, ìµœëŒ€ 30ë¶„
            'min_wait': 5,
            'max_wait': min(los_stats['q75'] * 3, 120),  # 75ë¶„ìœ„ì˜ 3ë°°ë¥¼ ë¶„ìœ¼ë¡œ, ìµœëŒ€ 120ë¶„
            'emergency_factor': 0.3,  # ì‘ê¸‰ í™˜ìëŠ” 30% ëŒ€ê¸°ì‹œê°„
            'peak_multiplier': 1.5 + (los_stats['std'] / los_stats['mean'])  # ë³€ë™ì„± ë°˜ì˜
        }

        # ì—°ë ¹ë³„ íŒ¨í„´
        combined['queue_patterns']['age_patterns'] = patient_patterns['age_groups']

        # ì„±ë³„ íŒ¨í„´
        combined['queue_patterns']['gender_patterns'] = patient_patterns['gender_distribution']

        return combined

    def save_patterns(self, patterns):
        """íŒ¨í„´ì„ JSON íŒŒì¼ë¡œ ì €ì¥"""
        output_dir = os.path.join('data', 'emrbots_patterns')
        os.makedirs(output_dir, exist_ok=True)

        output_file = os.path.join(output_dir, 'hospital_patterns.json')
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(patterns, f, indent=2, ensure_ascii=False, default=str)

        self.stdout.write(f"\nğŸ’¾ íŒ¨í„´ ì €ì¥ ì™„ë£Œ: {output_file}")

    def print_analysis_summary(self, patterns):
        """ë¶„ì„ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        self.stdout.write('\n' + '=' * 60)
        self.stdout.write('ğŸ“Š EMRBots ë°ì´í„° ë¶„ì„ ìš”ì•½')
        self.stdout.write('=' * 60)

        # ì…ì› íŒ¨í„´
        self.stdout.write('\nğŸ¥ ì…ì› íŒ¨í„´:')
        los = patterns['admissions']['length_of_stay']
        self.stdout.write(f"   - í‰ê·  ì…ì› ê¸°ê°„: {los['mean']:.1f}ì‹œê°„ ({los['mean']/24:.1f}ì¼)")
        self.stdout.write(f"   - ì¤‘ì•™ê°’: {los['median']:.1f}ì‹œê°„")

        # í™˜ì íŒ¨í„´
        self.stdout.write('\nğŸ‘¥ í™˜ì ë¶„í¬:')
        age_dist = patterns['patients']['age_distribution']
        self.stdout.write(f"   - í‰ê·  ì—°ë ¹: {age_dist['mean']:.1f}ì„¸")

        age_groups = patterns['patients']['age_groups']
        for group, ratio in age_groups.items():
            self.stdout.write(f"   - {group}ì„¸: {ratio*100:.1f}%")

        # ê²€ì‚¬ íŒ¨í„´
        self.stdout.write('\nğŸ§ª ê²€ì‚¬ íŒ¨í„´:')
        labs = patterns['labs']['labs_per_admission']
        self.stdout.write(f"   - ì…ì›ë‹¹ í‰ê·  ê²€ì‚¬: {labs['mean']:.1f}íšŒ")

        # ëŒ€ê¸°ì—´ íŒ¨í„´
        self.stdout.write('\nâ° ìƒì„±ëœ ëŒ€ê¸°ì—´ íŒ¨í„´:')
        queue = patterns['queue_patterns']

        # ê°€ì¥ í˜¼ì¡í•œ ì‹œê°„
        hourly = queue['hourly_congestion']
        peak_hour = max(hourly.items(), key=lambda x: x[1])
        self.stdout.write(f"   - í”¼í¬ ì‹œê°„: {peak_hour[0]}ì‹œ (í˜¼ì¡ë„ {peak_hour[1]:.2f})")

        # ê°€ì¥ í•œì‚°í•œ ì‹œê°„
        quiet_hour = min(hourly.items(), key=lambda x: x[1])
        self.stdout.write(f"   - í•œì‚°í•œ ì‹œê°„: {quiet_hour[0]}ì‹œ (í˜¼ì¡ë„ {quiet_hour[1]:.2f})")

        # ë¶€ì„œë³„ ë¶„í¬
        self.stdout.write('\nğŸ¢ ë¶€ì„œë³„ ì˜ˆìƒ ë¶„í¬:')
        dept_dist = queue['department_distribution']
        sorted_depts = sorted(dept_dist.items(), key=lambda x: x[1], reverse=True)
        for dept, ratio in sorted_depts[:5]:
            self.stdout.write(f"   - {dept}: {ratio*100:.1f}%")

        # ëŒ€ê¸°ì‹œê°„ íŒ¨í„´
        wait_patterns = queue['wait_time_patterns']
        self.stdout.write(f"\nâ±ï¸ ëŒ€ê¸°ì‹œê°„ íŒ¨í„´:")
        self.stdout.write(f"   - ê¸°ë³¸ ëŒ€ê¸°ì‹œê°„: {wait_patterns['base_wait']:.0f}ë¶„")
        self.stdout.write(f"   - ìµœëŒ€ ëŒ€ê¸°ì‹œê°„: {wait_patterns['max_wait']:.0f}ë¶„")
        self.stdout.write(f"   - í”¼í¬ ì‹œê°„ ë°°ìˆ˜: {wait_patterns['peak_multiplier']:.2f}x")

        self.stdout.write('=' * 60)